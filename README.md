# Проект антифрод-системы для банковских транзакций

## Цели проектируемой антифрод-системы

На основе требований заказчика сформулированы следующие цели:

1. **Снижение финансовых потерь:** Снизить ежемесячный ущерб клиентов от мошеннических операций до уровня, не превышающего 500 тыс. рублей
2. **Минимизация ложных срабатываний:** Обеспечить долю ложных срабатываний ниже 5% для предотвращения оттока клиентов
3. **Обеспечение высокой производительности:** Обрабатывать пиковую нагрузку до 400 транзакций в секунду с задержкой < 1-2 секунды
4. **Соблюдение сроков и бюджета:** Реализовать проект в течение 6 месяцев в рамках бюджета 10 млн рублей
5. **Обеспечение конфиденциальности данных:** Исключить утечку конфиденциальных данных клиентов

## Выбор метрики машинного обучения

**Рекомендуемая метрика для оптимизации: Fβ-Score с β = 2 (F2-Score)**

### Аргументация выбора:

- **Точность (Accuracy)** - неприменима из-за сильной несбалансированности данных (2% мошенничества)
- **Precision (Точность)** - критически важна для контроля ложных срабатываний (< 5%)
- **Recall (Полнота)** - критически важна для минимизации финансовых потерь
- **F2-Score** - оптимальный баланс с приоритетом на Recall, так как пропуск мошенничества дороже ложного срабатывания

**Итоговый подход:** Оптимизация F2-Score при гарантированном соблюдении условия Precision > 95%

## Анализ проекта с использованием MISSION Canvas

| Компонент | Анализ для антифрод-системы |
|-----------|-----------------------------|
| **Metrics** | **Бизнес-метрики:** Ежемесячный ущерб (< 500 тыс. руб.), Отток клиентов (< 5% ложных срабатываний)<br>**ML-метрики:** F2-Score, Precision (>95%), Recall<br>**Системные метрики:** Задержка (< 1 сек.), Пропускная способность (400 транз/сек.) |
| **Infrastructure** | **Облачная инфраструктура:**<br>• Обучение: AWS SageMaker / Google Vertex AI<br>• Обслуживание: Kubernetes / AWS Lambda<br>• Обработка данных: Apache Kafka / AWS Kinesis |
| **Source of Data** | **Формат:** CSV-файлы с транзакциями<br>**Проблемы:** Неэффективность CSV для потоковой обработки, конфиденциальность данных<br>**Решение:** Шифрование данных (at-rest и in-transit), надежный ingestion pipeline |
| **Skills** | **Команда:** Data Scientist, ML Engineer, Data/Software Engineer, DevOps/Cloud Engineer |
| **Interpretation** | **Требования:** Объяснимость решений (SHAP, LIME), дашборды для аналитиков, прозрачность работы системы |
| **Objectives** | **Конечная цель:** Автоматическое отклонение мошеннических транзакций в реальном времени<br>**Тактическая цель (3 месяца):** Работающий прототип для A/B тестирования |
| **Nature of Problem** | **Тип:** Бинарная классификация<br>**Особенности:** Несбалансированные данные, Concept Drift, онлайн-inference, адаптивность мошенников |

## Декомпозиция системы

Система разбита на следующие функциональные модули:

1. **Data Ingestion & Stream Processing Pipeline**
   - Прием и предобработка потоковых данных
   - Обогащение транзакций дополнительными признаками

2. **Feature Store & Storage**
   - Хранилище признаков в реальном времени и исторических данных
   - Обеспечение согласованности между обучением и обслуживанием

3. **ML Model Serving (Inference Service)**
   - Низколатентный микросервис для оценки транзакций
   - Возврат скора мошенничества и бинарного решения

4. **Orchestration & Decision Engine**
   - Принятие финального решения на основе скора и бизнес-правил
   - Интеграция с системой онлайн-платежей

5. **ML Training & Retraining Pipeline**
   - Автоматизированное обучение и валидация моделей
   - Борьба с Concept Drift через периодическое переобучение

6. **Monitoring & Observability**
   - Мониторинг данных и дрейфа модели
   - Отслеживание бизнес- и системных метрик

## Декомпозиция на S.M.A.R.T. задачи

### 1. EDA и разработка признаков
- **S:** Анализ исторических данных за 12 месяцев, генерация 20+ признаков
- **M:** Ноутбук с визуализациями, документация признаков, гипотезы о паттернах
- **A:** Выполнимо Data Scientist за 3 недели
- **R:** Фундамент для построения ML-модели
- **T:** 3 недели

### 2. Разработка и тестирование прототипов ML-моделей
- **S:** Обучение 3+ типов моделей (Logistic Regression, Random Forest, Gradient Boosting)
- **M:** F2-Score > [целевое значение], Precision > 95% на тестовой выборке
- **A:** Использование Scikit-learn, XGBoost
- **R:** Прямое достижение целевых показателей качества
- **T:** 4 недели

### 3. Развертывание ML-модели как облачного микросервиса
- **S:** Docker-контейнер с REST API, A/B тестирование на 5% трафика
- **M:** Задержка < 1 сек. при нагрузке 50 транз/сек, сбор предсказаний
- **A:** ML Engineer + DevOps
- **R:** Оценка работы в "боевых" условиях
- **T:** 3 недели

### 4. Реализация потоковой обработки данных
- **S:** Настройка Kinesis/Kafka, обогащение транзакций в реальном времени
- **M:** Обработка 400 транз/сек с end-to-end задержкой < 2 секунд
- **A:** Data/Software Engineer
- **R:** Критически для производительности системы
- **T:** 5 недели

### 5. Внедрение системы мониторинга
- **S:** Дашборды Grafana, алерты на data drift и concept drift
- **M:** Алерты при отклонениях, дашборд за 30 дней
- **A:** ML Engineer
- **R:** Обеспечение долгосрочной стабильности
- **T:** 3 недели
